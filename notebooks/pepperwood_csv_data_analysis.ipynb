{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Process the CSV data from Pepperwood\n",
        "\n",
        "Authors: Rohan and Daniel"
      ],
      "metadata": {
        "id": "9P01MtODKJux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVZ7iDEqT6Ft"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive to import data\n",
        "# Do this first since it will prompt authentication\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pathlib # Nicer IO than the os library\n",
        "from tqdm import tqdm  # Progress bar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables since the pepperwood code version does not include headers\n",
        "# It would also be possible to put this in a config.yml or similar format.\n",
        "BASE_HEADERS = ['datetime', 'from_node']\n",
        "NETWORK_HEADERS = ['rxSnr', 'hopLimit', 'rxRssi', 'hopStart']\n",
        "\n",
        "SENSOR_HEADERS = {\n",
        "    \"device_metrics\":   ['batteryLevel', 'voltage', 'channelUtilization', 'airUtilTx'],\n",
        "    \"bme688\":           ['temperature', 'relativeHumidity', 'barometricPressure', 'gasResistance', 'iaq'],\n",
        "    \"ina260\":           ['ch3Voltage', 'ch3Current'],\n",
        "    \"pmsa003i\":         ['pm10Standard', 'pm25Standard', 'pm100Standard', 'pm10Environmental', 'pm25Environmental', 'pm100Environmental']\n",
        "}\n",
        "SENSOR_NAMES = SENSOR_HEADERS.keys()\n",
        "\n",
        "FULL_DATA_HEADERS = {\n",
        "    sensor: BASE_HEADERS + SENSOR_HEADERS[sensor] + NETWORK_HEADERS \\\n",
        "        for sensor in SENSOR_NAMES\n",
        "}\n",
        "\n",
        "FOLDERPATH = '/content/drive/Shareddrives/SMesh: Sustainability Radio Sensor Networks/smesh_field_data/pepperwood_campaign_2024-11-07_to_2024-11-17/'\n",
        "\n",
        "\n",
        "def fix_incomplete_csv(csv_filename: pathlib.Path, sensor: str) -> pathlib.Path:\n",
        "    \"\"\"\n",
        "    Due to a mix in read_aqi.py and network_test.py. There is a mismatch in the\n",
        "    number of columns. Pandas cannot handle this and we need to add more commas\n",
        "    to the CSV to compliment.\n",
        "\n",
        "    This file would not be needed if the data was logged consistently :)\n",
        "    \"\"\"\n",
        "    expected_comma_number = len(FULL_DATA_HEADERS[sensor]) - 1\n",
        "\n",
        "    # Since python type hints are suggestions\n",
        "    csv_filename = pathlib.Path(csv_filename)\n",
        "    csv_filename_to_modify = csv_filename.with_name(\n",
        "        csv_filename.stem + '_modified' + csv_filename.suffix)\n",
        "\n",
        "    # Now add the commas\n",
        "    with open(csv_filename, 'r') as infile, \\\n",
        "            open(csv_filename_to_modify, 'w') as outfile:\n",
        "\n",
        "        for curr_line in tqdm(infile, desc=\"writing modified csv\"):\n",
        "            # count the number of commas\n",
        "            num_commas = curr_line.count(',')\n",
        "            num_missing_commas = expected_comma_number - num_commas\n",
        "            assert num_missing_commas >= 0, \\\n",
        "                f\"Expected {expected_comma_number} commas, but found {num_commas}\"\n",
        "\n",
        "            # add the commas at the end (fortunately since the network values\n",
        "            # are at the end, this is simpler)\n",
        "            modified_line = curr_line.rstrip('\\n') + \\\n",
        "                                \",\" * num_missing_commas + '\\n'\n",
        "            outfile.write(modified_line)\n",
        "\n",
        "    # Check that the new file exists\n",
        "    if not csv_filename_to_modify.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Could not find copied file at {csv_filename_to_modify}\")\n",
        "\n",
        "    return csv_filename_to_modify\n",
        "\n",
        "\n",
        "\n",
        "def read_csv_data_from_logger(logger: str, folderpath: str, sensor_list: list,\n",
        "                              extension: str = \".csv\") -> dict:\n",
        "    \"\"\"\n",
        "    Find the relevant data read from a specified logger node and form a pandas\n",
        "    dataframe for each of the datasets.\n",
        "\n",
        "    Inputs:\n",
        "        folderpath: str    - A string to the folder. In colab, it likely starts\n",
        "                             with '/content/drive/Shareddrives/'\n",
        "\n",
        "    Ouputs:\n",
        "        data_dfs : dict    - A dictionary of pandas dataframes\n",
        "    \"\"\"\n",
        "    data_dfs = {}\n",
        "\n",
        "    for sensor in sensor_list:\n",
        "        print(\"Trying to open data for\", sensor)\n",
        "        data_path = pathlib.Path(folderpath + logger + \"_\" + sensor + extension)\n",
        "        if not data_path.exists():\n",
        "            print(f\"No data for {sensor}. Used the following path: {data_path}\")\n",
        "            continue\n",
        "\n",
        "        # FOR PEPPERWOOD\n",
        "        mod_data_path = fix_incomplete_csv(data_path, sensor)\n",
        "        print(\"\\nFixed CSV\")\n",
        "\n",
        "        # The \"header=None\" means that the file does NOT have headers\n",
        "        # The \"parse_dates=[0]\" means that the zeroth column includes datetime\n",
        "        # objects.\n",
        "        data_dfs[sensor] = pd.read_csv(mod_data_path, header=None, parse_dates=[0])\n",
        "\n",
        "        # Since we do not have the headers, we need to add them\n",
        "        data_dfs[sensor].columns = FULL_DATA_HEADERS[sensor]\n",
        "        # Include the short name out of convenience\n",
        "        data_dfs[sensor]['from_short_name'] = data_dfs[sensor]['from_node'].str[-4:]\n",
        "\n",
        "        print(sensor, \"completed!\\n\")\n",
        "\n",
        "    return data_dfs"
      ],
      "metadata": {
        "id": "iZYaIZq1VCMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pepperwood_data_dfs = read_csv_data_from_logger(\"62e4\", FOLDERPATH, SENSOR_NAMES)"
      ],
      "metadata": {
        "id": "Rjhdck0LOSBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_all_sensor_variables(data_dict: dict, sensor: str):\n",
        "    \"\"\"\n",
        "    Plot each sensor variable by row\n",
        "    \"\"\"\n",
        "    col_id = 'from_short_name'\n",
        "    sensor_vars = SENSOR_HEADERS[sensor]\n",
        "    num_vars = len(sensor_vars)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows = num_vars, ncols=1,\n",
        "                             figsize=(12, 3 * num_vars), sharex=True)\n",
        "\n",
        "    for node_name, node_data in data_dict[sensor].groupby(col_id):\n",
        "        for var_id, sensed_var in enumerate(sensor_vars):\n",
        "            axes[var_id].scatter(x='datetime', y=sensed_var,\n",
        "                           data=node_data, label=node_name, s=1)\n",
        "            # axes[var_id].plot(x='datetime', y=sensed_var,\n",
        "            #                   data=node_data, label=node_name)\n",
        "\n",
        "    for var_id, sensed_var in enumerate(sensor_vars):\n",
        "        axes[var_id].grid(True)\n",
        "        axes[var_id].set_ylabel(sensed_var)\n",
        "        axes[var_id].legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n",
        "                            markerscale=3)\n",
        "\n",
        "        # if var_id == 0:\n",
        "        #     axes[var_id].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        # else:\n",
        "        #     axes[var_id].get_legend().remove()\n",
        "\n",
        "    curr_xlims = plt.xlims()\n",
        "    print(f\"Current xlims are {curr_xlims}\")\n",
        "    plt.xlabel('Date and Time')\n",
        "\n",
        "    return fig, axes"
      ],
      "metadata": {
        "id": "yFjYDLCKbjY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plot_all_sensor_variables(pepperwood_data_dfs, sensor='bme688')"
      ],
      "metadata": {
        "id": "yKYEDELIdYQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plot_all_sensor_variables(pepperwood_data_dfs, sensor='device_metrics')"
      ],
      "metadata": {
        "id": "vtH1iIWae0Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plot_all_sensor_variables(pepperwood_data_dfs, sensor='ina260')"
      ],
      "metadata": {
        "id": "XhV9I4Rde5A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plot_all_sensor_variables(pepperwood_data_dfs, sensor='pmsa003i')"
      ],
      "metadata": {
        "id": "lMvM7LvSe9r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things left to do:\n",
        "\n",
        "\n",
        "*   Night time\n",
        "*   Events dictionary (e.g., Fire start, Fire end, Rain start)\n",
        "*   Date time bounds to isolate days\n",
        "*   Dew point calculation from temperature and relative humidity\n",
        "*   Network data plots\n",
        "*   Move to GitHub\n",
        "*   Moving average (correctly in time)\n",
        "*   PMSA semilogy plots\n",
        "*   PMSA correlation plots\n",
        "*   Histogram of the number of packets\n",
        "*   Packet frequency plots (e.g., how regular and how many dropped packets)\n",
        "*   Purple Air Data for comparison"
      ],
      "metadata": {
        "id": "CNNZ528FhQ02"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qz_pBZmxhno1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}